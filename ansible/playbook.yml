# ---
# - name: D√©ploiement Big Data s√©par√©
#   hosts: localhost
#   vars:
#     repo_dest_kafka: "/home/mathys/Infra-et-orch-de-donn-es"
#     repo_dest_hadoop: "/home/mathys/Infra-et-orch-de-donn-es/Hadoop"
#     repo_dest_hive: "/home/mathys/Infra-et-orch-de-donn-es/Hive"

#   tasks:
#     - name: Ensure Docker network exists
#       community.docker.docker_network:
#         name: infra-net
#         state: present

#     - name: üß± D√©marrer stack Kafka
#       command: docker compose up -d --build
#       args:
#         chdir: "{{ repo_dest_kafka }}"

#     - name: üß± D√©marrer stack Hadoop
#       command: docker compose up -d --build
#       args:
#         chdir: "{{ repo_dest_hadoop }}"

#     - name: ‚è≥ Attendre que HDFS soit pr√™t
#       shell: |
#         until docker exec hadoop-namenode hdfs dfs -ls /; do sleep 5; done
#       retries: 20
#       delay: 5

#     - name: üß± D√©marrer stack Hive
#       command: docker compose up -d --build
#       args:
#         chdir: "{{ repo_dest_hive }}"

#     - name: ‚è≥ Attendre que Hive soit pr√™t
#       shell: |
#         until docker exec hadoop-hive hive -e 'SHOW DATABASES;' >/dev/null 2>&1; do sleep 5; done
#       retries: 20
#       delay: 5

#     - name: ‚úÖ V√©rification Hive
#       shell: docker exec hadoop-hive hive -e 'SHOW DATABASES;'








---
- name: D√©ploiement complet Big Data avec Hive
  hosts: localhost
  vars:
    repo_dest_kafka: "/home/mathys/Infra-et-orch-de-donn-es"
    repo_dest_hadoop: "/home/mathys/Infra-et-orch-de-donn-es/Hadoop"
    repo_dest_scripts: "/home/mathys/Infra-et-orch-de-donn-es/Hadoop/python-container"
    repo_dest_data: "/home/mathys/Infra-et-orch-de-donn-es/Hadoop/data"
    hadoop_container: "hadoop-namenode"

  tasks:
    - name: Ensure Docker network infra-net exists
      community.docker.docker_network:
        name: infra-net
        state: present

    - name: üß± D√©marrer stack Kafka + PostgreSQL
      command: docker compose up -d --build
      args:
        chdir: "{{ repo_dest_kafka }}"

    - name: üåê D√©marrer stack Hadoop + Hive
      command: docker compose up -d --build
      args:
        chdir: "{{ repo_dest_hadoop }}"

    - name: ‚è≥ Attendre que HDFS soit pr√™t
      shell: |
        until docker exec {{ hadoop_container }} hdfs dfs -ls / >/dev/null 2>&1; do sleep 5; done
      retries: 20
      delay: 5

    # --- Copier Mapper, Reducer et CSV dans le conteneur si pr√©sents ---
    - name: Copier mapper.py dans le conteneur Hadoop
      command: docker cp {{ repo_dest_scripts }}/mapper.py {{ hadoop_container }}:/mapper.py
      ignore_errors: yes

    - name: Copier reducer.py dans le conteneur Hadoop
      command: docker cp {{ repo_dest_scripts }}/reducer.py {{ hadoop_container }}:/reducer.py
      ignore_errors: yes

    - name: Copier weapons.csv dans le conteneur Hadoop
      command: docker cp {{ repo_dest_data }}/weapons.csv {{ hadoop_container }}:/weapons.csv
      ignore_errors: yes

    - name: Copier run_hadoop_pipeline.sh dans le conteneur Hadoop
      command: docker cp {{ repo_dest_scripts }}/run_hadoop_pipeline.sh {{ hadoop_container }}:/run_hadoop_pipeline.sh
      ignore_errors: yes

    - name: Donner les droits d'ex√©cution aux scripts pr√©sents
      command: >
        docker exec {{ hadoop_container }} sh -c "
        for f in /mapper.py /reducer.py /run_hadoop_pipeline.sh; do
          if [ -f \$f ]; then chmod +x \$f; fi
        done || true"
      ignore_errors: yes
    # --- Lancer le pipeline Hadoop automatiquement si le script existe ---
    - name: ‚öôÔ∏è Lancer job Hadoop avec run_hadoop_pipeline.sh
      command: docker exec {{ hadoop_container }} bash -c "[ -f /run_hadoop_pipeline.sh ] && /run_hadoop_pipeline.sh || echo 'run_hadoop_pipeline.sh absent, skipping'"

    - name: ‚öôÔ∏è Charger r√©sultats dans Hive
      command: python3 insert_to_hive.py
      args:
        chdir: "{{ repo_dest_scripts }}"


