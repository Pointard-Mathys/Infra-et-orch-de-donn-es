# services:
#   hadoop-namenode:
#     image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
#     container_name: hadoop-namenode
#     environment:
#       - CLUSTER_NAME=hadoop
#       - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
#       - HDFS_CONF_dfs_webhdfs_enabled=true
#       - HDFS_NAMENODE_USER=root
#       - HDFS_DATANODE_USER=root
#       - HDFS_SECONDARYNAMENODE_USER=root
#     ports:
#       - "9871:9870"
#       - "9000:9000"
#     volumes:
#       - hadoop_data:/hadoop/dfs/namenode
#     command: tail -f /dev/null
#     networks:
#       - infra-net

#   hadoop-datanode:
#     image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
#     container_name: hadoop-datanode
#     environment:
#       - CLUSTER_NAME=hadoop
#       - NAMENODE_URI=hdfs://hadoop-namenode:9000
#       - HDFS_CONF_dfs_webhdfs_enabled=true
#       - HDFS_DATANODE_USER=root
#       # - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
#       # - PATH=$JAVA_HOME/bin:$PATH
#     depends_on:
#       - hadoop-namenode
#     volumes:
#       - hadoop_data:/hadoop/dfs/datanode
#     command: tail -f /dev/null
#     networks:
#       - infra-net

#   data-exporter:
#     build: ./python-container
#     container_name: data-exporter
#     depends_on:
#       - hadoop-namenode
#     environment:
#       - POSTGRES_HOST=postgres
#       - POSTGRES_DB=postgresdb
#       - POSTGRES_USER=postgresuser
#       - POSTGRES_PASSWORD=postgrespassword
#     volumes:
#       - ./data:/Hadoop/data
#     networks:
#       - infra-net

#   hbase:
#     image: harisekhon/hbase
#     container_name: hbase
#     environment:
#       HBASE_MANAGES_ZK: "true"
#     ports:
#       - "16010:16010"
#       - "9090:9090"
#     depends_on:
#       - hadoop-namenode
#     networks:
#       - infra-net

# volumes:
#   hadoop_data:

# networks:
#   infra-net:
#     external: true




services:
  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - HDFS_SECONDARYNAMENODE_USER=root
    ports:
      - "9871:9870"
      - "9000:9000"
    volumes:
      - hadoop_data:/hadoop/dfs/namenode
    # command: tail -f /dev/null
    networks:
      - infra-net

  # hadoop-datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
  #   container_name: hadoop-datanode
  #   environment:
  #     - CLUSTER_NAME=hadoop
  #     - NAMENODE_URI=hdfs://hadoop-namenode:9000
  #     - HDFS_CONF_dfs_webhdfs_enabled=true
  #     - HDFS_DATANODE_USER=root
  #     # - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
  #     # - PATH=$JAVA_HOME/bin:$PATH
  #   depends_on:
  #     - hadoop-namenode
  #   volumes:
  #     - hadoop_data:/hadoop/dfs/datanode
  #   command: tail -f /dev/null
  #   networks:
  #     - infra-net


  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_DATANODE_USER=root
    depends_on:
      - hadoop-namenode
    volumes:
      - hadoop_data:/hadoop/dfs/datanode
    # command: tail -f /dev/null
    networks:
      - infra-net


  data-exporter:
    build: ./python-container
    container_name: data-exporter
    depends_on:
      - hadoop-namenode
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=postgresdb
      - POSTGRES_USER=postgresuser
      - POSTGRES_PASSWORD=postgrespassword
    volumes:
      - ./data:/Hadoop/data
    networks:
      - infra-net


volumes:
  hadoop_data:

networks:
  infra-net:
    external: true
